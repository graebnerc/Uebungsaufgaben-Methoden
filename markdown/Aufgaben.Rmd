---
title: "Übungsaufgaben R-Tutorium"
date: "Sommersemester 2021"
output:
  rmarkdown::html_document:
    theme: cosmo
    number_sections: true
  pdf_document: 
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.align = "center", out.width = '75%', 
  warning = FALSE, message = FALSE)
```

```{r, include=FALSE}
library(here)
library(data.table)
library(knitr)
```


# Grundlagen

## Grundrechenarten

Führen Sie die folgenden Rechnungen aus:

$$10+25$$
$$50\cdot 2$$

$$\frac{27}{4}$$
$$500-650$$

$$2^4$$

$$\sqrt{3}\cdot 60$$

$$50 \cdot (4+2)^3$$

## Rechnungen mit Zwischenschritten

Führen Sie die folgende Rechnung aus. Speichern Sie dabei die Zwischenergebnisse
immer explizit ab und verwenden Sie sie für den nächsten Schritt weiter.
Geben sie am Ende das Gesamtergebnis aus.

\begin{align*}
a &= 10 + 25\\
b &= a \cdot 40\\
c &= b - 100\\
d &= c \cdot 3\\
e &= \sqrt{d}\\
f &= \frac{e}{1000}\\
g &= f^3
\end{align*}

*Vorsicht:* Überschreiben Sie keine `R`-spezifischen Befehle, wie z.B. `c`!

## Vektorentypen und Dataframes

### Tests auf Datentypen

Wenden Sie einen geeigneten Test an, um den Typ der atomaren Vektoren `100` und 
`"Tutorium"` angeben zu können.

Testen Sie explizit ob es sich bei den atomaren Vektoren um ein Objekt vom Typ
`double`, bzw. `character` handelt.

### Transformation von Datentypen

In dem folgenden Chunk wird eine Zahl als `character` abgespeichert. Ergänze 
den Code, sodass der atomare Vektor wieder als `double` gespeichert wird.
Überprüfe dann mit einem Test, ob die Transformation erfolgreich war und 
multipliziere das Ergebnis mit `2`.

```{r}
at_vec <- "2"
```


### Listen und DataFrames

Erstelle eine Liste mit drei Elemnten, in denen jeweils die Zahlen von
`50 - 55`, `60 - 65` und `70 - 75` angegeben werden. Transformiere
die Liste dann in einen Dataframe.

### Manuelle Konstruktion eines DataFrames

Für diese Aufgabe sollst du eigenständig einen Data Frame erstellen. In diesem
soll für die Bundesländer `Berlin`, `Hamburg` und `Bremen` die Fläche in 
Quadratkilometer angegeben werden. Für `Berlin` sind dies ungefähr `892`,
für `Hamburg` ungefähr `755` und für `Bremen` ungefähr `419`.
Welchen Typ haben die atomaren Vektoren in den Spalten?

Wiederhole das Erstellen des DataFrames, aber erstelle diesmal einen 
`tibble`.

### DataFrames und Listen (optional)

Welchen Typ hat ein DataFrame? Welchen Typ hat ein `tibble`? 
Welchen Typ hat eine Liste? Was sagt uns das
über die zugrundeliegende Objektstruktur in `R`?

# R-Markdown

TBA

# Datenaufbereitung

## Filtern und Übersetzen

Ladet bitte den Datensatz `ProbSet2_BIP-Konsum_tidy.csv` herunter. Führt dann
folgende Arbeitsschritte aus:

1. Filtert den Datensatz so, dass er nur noch die zwischen den Jahren 1997 und 
2015 erhobenen Beobachtungen enthält.

2. Nehmen wir an, ihr müsstet euren Datensatz für ein englisches Publikum
formulieren. Benennt benennt daher die Spalte `Jahr` in `Year`, 
`Konsumausgaben` in `ConsumerSpending` und `BIP` in `GDP` um.

## Herunterladen eines OECD-Datensatzes

Besorgt euch Informationen über die gesamte Staatsverschuldung 
(offene Schulden der Zentralregierung) als Prozent des BIP aus der Datanbank 
der `OECD`, die ihr über folgende Website erreichen könnt:
[https://stats.oecd.org/](https://stats.oecd.org/).

*Hinweis:* Den resultierenden Datensatz könnt ihr als `GovDebt.csv` herunterladen.
Dieser bildet den Ausgangspunkt für die nächste Aufgabe und kann auch zur
Ergebniskontrolle dienen.

## Aufbereitung des OECD Datensatzes

Bereitet den gerade heruntergeladenen Datensatz (den ihr ansonsten auch
als `GovDebtOECD.csv` im Ordner `data` findet) auf indem ihr nur noch die 
Variablen `Country`, `TIME` und `Value` behaltet und die Daten auf Beobachtungen 
für Deutschland zwischen 2005 und 2010 beschränkt. Stellt sicher, dass ihr für
jede Jahr-Land Kombination tatsächlich nur eine Beobachtung im Datensatz habt.

## Lange und breite Datensätze kombinieren

Laden Sie sich Daten zum "adjusted wage share" von der [AMECO Datenbank](https://ec.europa.eu/info/business-economy-euro/indicators-statistics/economic-databases/macro-economic-database-ameco/ameco-database_en)
(`Gross Domestic Product (Income Approach), Labour Costs`)
und Daten zu Einkommensungleichheit (gemessen durch den Post-Steuer-Gini Index) 
von der *Standardized World Income Inequality Database* 
([SWIID](https://fsolt.org/swiid/)) herunter.
Bei der SWIID brauchen Sie nur den 'Summary' Datensatz.
Kombinieren Sie die Datensätze und transformieren Sie sie in 
eine aufgeräumte Form sodass er den Anforderungen an 'tidy data' entspricht und
dass es keine fehlenden Werte gibt.

Fasen Sie danach die Daten zusammen indem Sie Durchschnitte und 
Standardabweichungen für die jeweiligen Kontinente berechnen. 

> **Tipp:** Um die Kontinente zu den Ländern herauszufinden können Sie das Paket
`countrycode` verwenden. Es kennt einen 'Code' `continent` in den Sie jedes 
Land 'übersetzen' können.

Der Datensatz sollte am Ende ungefähr so aussehen:

```{r, echo=FALSE}
ameco_swiid_data <- fread(here("data/ameco_swiid_tidy.csv"))
knitr::kable(ameco_swiid_data)
```

# Visualisierung

## Liniengraph zu privaten Krankenversicherungen in Deutschland

Verwendet für die Aufgabe den Datensatz `PrivateInsuranceGermany.csv`. Dieser
enthält die Daten darüber, welcher Prozentsatz der Bevölkerung im Zeitraum von
1995 bis 2019 in Deutschland privatversichert war.

Ziel der Übung ist es, dass ihr am Ende eine vollständige Grafik erstellt habt, 
in welcher der Prozentsatz der Privatversicherten in einem Liniengraph
dargestellt wird, die Achsen beschriftet sind und sowohl ein Titel als auch
die Quellenangabe hinzugefügt werden.

Orientieren könnt ihr euch dabei an folgenden Angaben:

Name y-Achse: `Anteil privatversicherter Personen in %`

Titel: `Entwicklung der Privatversicherungen in Deutschland`

Untertitel: `Zeitraum von 1991 bis 2018`

Caption: `Daten: OECD Statistics`

Am Ende soll die Abbildung ungefähr folgendermaßen aussehen:

```{r, echo=FALSE}
knitr::include_graphics(here("output/vis_priv_krankenvers.png"))
```

## Ein Balkendiagramm

Eine sehr schöne Diskussion verschiedener Visualisierungsmöglichkeiten 
bietet das Paper 'An Economist’s Guide to Visualizing Data' von 
Jonathan Schwabish (siehe
[hier](https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.28.1.209)
).
Auf S. 216 findet sich folgende Abbildung:

```{r, echo=FALSE}
knitr::include_graphics(here("output/vis_schwabisch_expl.png"))
```

Replizieren Sie diese so gut wie möglich und verwenden Sie dabei
folgende manuell erstellten Daten:

```{r}
werte <- tibble::tibble(
  Gruppe = c(
    "Finish no school", 
    "Finish 1 year", 
    "Finish 3 years",
    "Graduate, 2.0 GPA",
    "Graduate, 3.0 GPA",
    "Graduate, 3.75 GPA"),
  Einkommen = c(
    480, 510, 620,
    800, 920, 1050
  ))
```


## Zwei Balkendiagramme

Für diese Aufgabe beziehen wir uns direkt auf den Datensatz, den wir in der
Aufgabe `Lange und breite Datensätze kombinieren` im Abschnitt
`Datenaufbereitung` erstellt haben.
Falls ihr die entsprechende Aufgabe nicht gelöst habt, ist das 
Zwischenergebnis auch unter `data/ameco_swiid_tidy.csv` verfügbar. 
Es empfiehlt sich aber, beide Aufgaben hintereinander und gemeinsam zu lösen.

Stellen Sie die Mittelwerte und Standardabweichungen in einem 
Balkendiagramm dar. Die Standardabweichung sollte durch einen
Whisker dargstellt werden, der sich nach oben und unten vom Mittelwert 
je um eine halbe Standardabweichung erstreckt.

Die resultierende Abbildung sollte ungefähr so aussehen:

```{r, echo=FALSE}
knitr::include_graphics(here("output/vis_ameco_swiid.png"))
```

> *Tipp 1*: Um zwei Plots in einer Abbildung zu kombinieren verwenden Sie
die Funktion `ggpubr::ggarrange()`. Aber Achtung: im Paket gibt es
auch eine Funktion `mutate()`, in Kombination mit dem Paket 
`dplyr` (enthalten im `tidyverse`) ist also Vorsicht geboten!

> *Tipp 2*: Für die Whisker im Balkendiagram können Sie die Funktion
`ggplot2::geom_errorbar()` verwenden.

# Formalia

TBA

# Regressionsanalyse I

TBA

# Monte-Carlo-Simulationen

## Der Zentrale Grenzwertsatz

Illustrieren Sie die Funktion des zentralen Grenzwertsatzes mit Hilfe einer
MCS am Beispiel des Mittelwerts einer Uniformverteilung.

## Das Gesetz der großen Zahl

Illustrieren Sie das Gesetz der großen Zahl indem Sie aus einer Normalverteilung
Stichproben unterschiedlicher Größe ziehen und deren Varianz und Mittelwert
abbilden.

## OLS und nicht-normalverteilte Fehler

Sie haben in der Vorlesung gelernt, dass die Normalverteilung der 
Fehlerterme häufig als optionale Annahme im OLS-Framework verwenet wird.
Untersuchen Sie die Implikationen von nicht-normalverteilten Fehlertermen
auf die Verteilung des OLS-Schätzers für unterschiedliche Stichprobengrößen
mit Hilfe einer MCS und interpretieren Sie die Ergebnisse.
Beziehen Sie sich der Einfachheit halber auf ein univariates Regressionsmodell.
Um nicht-normalverteilte Fehlerterme zu generieren ziehen Sie Zufallszahlen aus
der $\chi^2$-Verteilung mit einem Freiheitsgrad und normalisieren Sie die 
Fehler, sodass sie einen Mittelwert von $0$ aufweisen (Sie können die
Funktion `scale()` verwenden).

# Regressionsanalyse II

TBA

# Regressionsanalyse III

TBA
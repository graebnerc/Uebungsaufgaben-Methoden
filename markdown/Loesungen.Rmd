---
title: "Übungsaufgaben R-Tutorium - Lösungen"
date: "Sommersemester 2021"
output:
  rmarkdown::html_document:
    theme: cosmo
    number_sections: true
  pdf_document: 
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.align = "center", out.width = '50%', 
  warning = FALSE, message = FALSE)
```

# Grundlagen

## Grundrechenarten

$$10+25$$

```{r}
10 + 25
```

$$50\cdot 2$$

```{r}
50 * 2
```

$$\frac{27}{4}$$

```{r}
27 / 4
```

$$500-650$$

```{r}
500 - 650
```

$$2^4$$

```{r}
2^4 # Alternativ: 2**4
```

$$\sqrt{3}\cdot 60$$

```{r}
sqrt(3) * 60
```

$$50 \cdot (4+2)^3$$

```{r}
50 * (4 + 2)^3
```

## Rechnungen mit Zwischenschritten

```{r}
a_  <- 10 + 25
b_  <- a_ * 40
c_ <- b_ - 100
d_ <- c_ * 3
e_ <- sqrt(d_)
f_ <- e_ / 1000
g_ <- f_^3
print(g_)
```


*Hinweis*: Um zu vermeiden, dass originäre `R`-Befehlte wie `c` überschrieben
werden, wurden in der Lösung den Buchstaben immer ein `_` als 
Variablenname angefügt
Bevor man einen Variablennamen vergibt, sollte man immer durch Eingabe in der
Konsole überprüfen, ob dieser Name bereits vergeben ist.
Bei `c` würde hätte man dann unmittelbar gemerkt, dass es sich hier bereits
um eine Funktion handelt:

```{r}
c
```

Man bekommt zwar keine Fehlermeldungen, wenn solche internen Funktionen
überschrieben werden, das sollte aber unbedingt vermieden werden.

## Vektorentypen und Dataframes

### Tests auf Datentypen

```{r}
typeof(100)
typeof("Tutorium")
is.double(100)
is.character(100)
is.double("Tutorium")
is.character("Tutorium")
```

### Transformation von Datentypen

```{r}
at_vec <- "2"
at_vec_double <- as.double(at_vec)
is.double(at_vec_double)
```

```{r}
at_vec_double * 2
```


### Listen und DataFrames

```{r}
Liste_1 <- list(
  "a" = 50:55,
  "b" = 60:65,
  "c" = 70:75
)
Liste_1
```

```{r}
Data_Frame_1 <- as.data.frame(Liste_1)
Data_Frame_1
```

### Manuelle Konstruktion eines DataFrames

```{r}
Bundeslaender <- data.frame(
  "Bundesland" = c("Berlin", "Hamburg", "Bremen"),
  "Flaeche" = c(892, 755, 419)
)
Bundeslaender
```

```{r}
str(Bundeslaender)
```

Oder:

```{r}
typeof(Bundeslaender$Bundesland)
```

```{r}
typeof(Bundeslaender$Flaeche)
```

Erstellen eines `tibble`:

```{r}
require(tibble)
Bundeslaender <- tibble::tibble(
  "Bundesland" = c("Berlin", "Hamburg", "Bremen"),
  "Flaeche" = c(892, 755, 419)
)
Bundeslaender
```


### DataFrames und Listen (optional)

Welchen Typ hat ein DataFrame? Welchen Typ hat ein `tibble`? 
Welchen Typ hat eine Liste? Was sagt uns das
über die zugrundeliegende Objektstruktur in `R`?

```{r}
require(tibble)
list_expl <- list("a"=1:3, "b"=4:6)
data_frame_expl <- as.data.frame(list_expl)
tibble_expl <- tibble::as_tibble(list_expl)
```

```{r}
typeof(list_expl)
```

```{r}
typeof(data_frame_expl)
```

```{r}
typeof(tibble_expl)
```

Bei allen drei Objekten handelt es sich um Listen!
Das liegt daran, dass es sich beim DataFrame und beim Tibble nicht um 'genuine'
Typen handelt, sondern um so genannte S3-Klassen, welche die 'genuinen' 
Typen wie `list` mit bestimmten Features modifiziert. Das erkennen wir über 
Anwendung der Funktion
`class()`:

```{r}
class(list_expl)
```

```{r}
class(data_frame_expl)
```

```{r}
class(tibble_expl)
```

```{r}
is.data.frame(tibble_expl)
```

```{r}
is.data.frame(data_frame_expl)
```

Aber:

```{r}
tibble::is_tibble(data_frame_expl)
```

```{r}
tibble::is_tibble(tibble_expl)
```

Das hat mit der objektorientierten Struktur von R zu tun. Es ist in der Praxis
nur relevant wenn wir Operationen durchführen, die für unterschiedliche Klassen
unterschiedlich funktionieren. Das werden wir später z.B. bei der Funktion
`summary()` noch merken. Es ist aber in der Praxis zu Beginn weniger relevant.
Mehr Details gibt es im Skript und 
[hier](https://adv-r.hadley.nz/vectors-chap.html#s3-atomic-vectors).

# R-Markdown

TBA

# Datenaufbereitung

## Filtern und Übersetzen

Verwendete Pakete:

```{r}
require(tidyverse)
require(here)
require(data.table)
require(countrycode)
require(knitr)
```


Einlesen der Daten:

```{r}
daten_pfad <- here::here("data/BIP_Konsum.csv")

daten <- data.table::fread(
  daten_pfad, colClasses = c("double"))
head(daten, 3)
```

Filtern der Beobachtungen:

```{r}
daten_1997_2015 <- daten %>%
  dplyr::filter(Jahr > 1997 & Jahr < 2015)
```

Übersetzung:

```{r}
daten_uebersetzt <- daten %>%
  dplyr::rename(
    Year = Jahr,
    ConsumerSpending = Konsumausgaben,
    GDP = BIP
  )
head(daten_uebersetzt, 2)
```

Optionale Alternative bei der die Namen als `character` 
kodiert sind (nützlich für die Automatisierung):

```{r}
daten_uebersetzt <- daten %>%
  dplyr::rename(
    !!as.name("Year") := !!as.name("Jahr"),
    !!as.name("ConsumerSpending") := !!as.name("Konsumausgaben"),
    !!as.name("GDP") := !!as.name("BIP")
  )
head(daten_uebersetzt, 2)
```

## Herunterladen eines OECD Datensatzes

Geht auf der Website links über den Reiter
`Finance`auf den Tab `Central Government Debt`. Dort findet ihr eine
gleichnamige Tabelle, aus dem ihr die Daten herausziehen könnt
Folgende Einstellungen sind dabei notwendig, die ihr oben durch einen Klick auf
`Customize` vornehmen könnt:

Variable: `Total central government debt % of GDP`
Type: Stocks: `Outstanding Amounts`
Unit: `Percantage`
Frequency: `Annual`
Time Period: `2000 - 2010`
Countries: `Alle Länder von Australia bis United States`

Dann könnt ihr den Datensatz herunterladen und als `csv` speichern.

## Aufbereitung des OECD Datensatzes

1. Einlesen:

```{r}
Debt_Pfad <- here::here("data/GovDebt.csv")

Debt <- data.table::fread(Debt_Pfad)
str(Debt, vec.len = 3)
```

2. Auswahl der Zeilen:

```{r}
Debt_1 <- Debt %>%
  dplyr::select(Country, TIME, Value)

# Alternativ mit characters
Debt_1 <- Debt %>%
  dplyr::select(
    dplyr::all_of(c("Country", "TIME", "Value"))
    )
head(Debt_1, 2)
```

3. Filtern nach Deutschland und Zeitraum:

```{r}
Debt_1_Filtered <- Debt_1 %>%
  dplyr::filter(
    Country == "Germany",
    TIME >= 2005, 
    TIME <= 2010
  )
Debt_1_Filtered
```

Oder alle Schritte kombiniert mit Hilfe von `%>%`:

```{r}
debt_filtered <- data.table::fread(Debt_Pfad) %>%
  dplyr::select(
    dplyr::all_of(c("Country", "TIME", "Value"))
    ) %>%
  dplyr::filter(
    Country == "Germany",
    TIME >= 2005, 
    TIME <= 2010
  )
```


In jedem Fall sollte man immer verifizieren, ob die Länder-Jahre-Kombinationen
eindeutig sind, z.B. durch:

```{r}
debt_filtered_unique <- debt_filtered %>% 
  dplyr::distinct(Country, TIME, .keep_all = TRUE)
nrow(debt_filtered_unique) - nrow(debt_filtered)
```

Da beide Datensätze die gleiche Anzahl an Zeilen haben, gibt es keine
Duplikate. Es gibt verschiedene (und je nach Anwendung effizientere) Methoden
um Duplikatore zu finden, aber für die meisten Fälle ist `dplyr::distinct()`
ausreichend.

Bereitet den gerade heruntergeladenen Datensatz (den ihr ansonsten auch
als `GovDebtOECD.csv` im Ordner `data` findet) auf indem ihr nur noch die 
Variablen `Country`, `TIME` und `Value` behaltet und die Daten auf Beobachtungen 
für Deutschland zwischen 2005 und 2010 beschränkt. Stellt sicher, dass ihr für
jede Jahr-Land Kombination tatsächlich nur eine Beobachtung im Datensatz habt.

## Lange und breite Datensätze kombinieren

Nachdem wir die Daten heruntergeladen und unter 
`data/raw/AMECO7.txt` und `data/raw/swiid8_0_summary.csv`
gespeichert haben
transformieren wir beide Datensätze zunächst in die lange Form (beim SWIID ist 
die relevante Spalte der `gini_disp`):

```{r}
ameco_7 <- fread(
  here("data/raw/AMECO7.txt"), fill = T, header = T,
  colClasses = c(rep("character", 5), rep("double", 63))
  ) %>%
  filter(
    TITLE==paste("Adjusted wage share: total economy: as percentage of", 
                 "GDP at current prices (Compensation per employee as", 
                 "percentage of GDP at market prices per person employed.)")
    ) %>%
  select(
    -any_of(c("V68", "SUB-CHAPTER", "CODE", "TITLE", "UNIT"))
    ) %>%
  pivot_longer(
    names_to = "Jahr", values_to = "AWS", 
    cols = one_of(as.character(1960:2021))
    ) %>%
  mutate(Jahr=as.double(Jahr))

swiid <- fread(
  here("data/raw/swiid8_0_summary.csv"), 
  select = c("country"="character", 
             "year"="double", 
             "gini_disp"="double"))
```

Wir verwenden nun die Funktion `inner_join()`, da wir ja keine fehlenden
Werte haben wollen. 
Vorher übersetzen wir noch die Ländernamen beider Datensätze in das `iso3c`
Format:

```{r, warning=FALSE}
ameco_7 <- ameco_7 %>%
  mutate(
    COUNTRY=countrycode(COUNTRY, "country.name", "iso3c")
    ) %>%
  filter(!is.na(COUNTRY))

swiid <- swiid %>%
  mutate(
    country=countrycode(country, "country.name", "iso3c")
    ) %>%
  filter(!is.na(country))

full_data <- inner_join(
  ameco_7, swiid, 
  by=c("COUNTRY"="country", "Jahr"="year"))
```

Nun können wir noch die Kontinente hinzufügen und die gewünschten 
gruppierten deskriptiven Statistiken berechnen:

```{r}
final_data <- full_data %>%
  mutate(
    Region=countrycode(
      COUNTRY, origin = "iso3c", destination = "continent")
    ) %>%
  group_by(Region) %>%
  summarise(
    across(
      .cols = all_of(c("AWS", "gini_disp")), 
      .fns =  list(mean = ~mean(.x, na.rm=T), 
                   sd = ~sd(.x, na.rm=T)), 
      .groups = "drop")) 
knitr::kable(final_data)
```

```{r, echo=FALSE, eval=FALSE}
fwrite(final_data, file = here("data/ameco_swiid_tidy.csv"))
```

# Visualisierung

## Liniengraph zu privaten Krankenversicherungen in Deutschland

```{r}
require(tidyverse)
require(data.table)
require(scales)
require(here)
```

```{r}
daten_pfad <- here::here("data/PrivateInsuranceGermany.csv")

priv_vers_de <- data.table::fread(
  daten_pfad, colClasses = c("double", "double", "character")
  ) %>%
  ggplot2::ggplot(
  data = .,
  mapping = aes(x = Year, y = PercPop)
) +
  ggplot2::geom_line() +
  ggplot2::scale_x_continuous(name = "Jahr") + 
  ggplot2::scale_y_continuous(
    name = "Anteil Privatversicherungen", 
    labels = scales::percent_format(scale = 1, accuracy = 1),
    limits = c(0, 40)
    ) +
  ggplot2::labs(
    title = "Entwicklung der Privatversicherungen in Deutschland",
    subtitle = "Zeitraum von 1991 bis 2018",
    caption = "Daten: OECD Statistics"
  ) +
  theme_bw() +
  theme(
    panel.border = element_blank(),
    axis.line = element_line(),
    axis.title.x = element_blank()
  )
```

```{r, echo=FALSE}
ggsave(
  plot = priv_vers_de, 
  filename = here("output/vis_priv_krankenvers.png"), 
  width = 5, height = 3)
```

## Ein Balkendiagramm

```{r}
require(tidyverse)
```

```{r}
werte <- tibble::tibble(
  Gruppe = c(
    "Finish no school", 
    "Finish 1 year", 
    "Finish 3 years",
    "Graduate, 2.0 GPA",
    "Graduate, 3.0 GPA",
    "Graduate, 3.75 GPA"),
  Einkommen = c(
    480, 510, 620,
    800, 920, 1050
  ))

schwabisch_plot <- ggplot(
  data = werte, 
  mapping = aes(x=reorder(Gruppe, -Einkommen), y=Einkommen)
  ) +
  geom_bar(
    stat = "identity", width = 0.5, color="#13294b", fill="#13294b"
    ) + 
  scale_y_continuous(
    breaks = seq(0, 1200, 200), expand = expansion()
    ) +
  coord_flip() +
  labs(
    title = "Discounted Expected Lifetime Earnings, VN(t')", 
    subtitle = "(Income in thousands)", 
    caption = paste(
      "Author's calculations using numbers inferred from text",
      "in Stinebrickner and Stinebrickner (2013).")
    ) +
  theme_bw() +
  theme(panel.border = element_blank(), 
        axis.ticks = element_blank(), 
        axis.title = element_blank(), 
        axis.line = element_line(),
        panel.grid = element_blank(),
        plot.title = element_text(face = "bold"),
        panel.grid.major.x = element_line(colour = "grey"))
```


## Zweil Balkendiagramme

```{r}
require(data.table)
require(here)
library(scales)
require(tidyverse)
require(ggpubr)
```


```{r}
ameco_swiid_data <- fread(here("data/ameco_swiid_tidy.csv"))

aws_plot <- ggplot(
  data = ameco_swiid_data, 
  mapping = aes(x=Region, y=AWS_mean)
  ) +
  geom_bar(
    stat = "identity", width = 0.5, color="#13294b", fill="#13294b"
    ) +
  geom_errorbar(
    aes(ymin=AWS_mean-0.5*AWS_sd, ymax=AWS_mean+0.5*AWS_sd), 
    width = 0.4, color = "grey"
    ) +
  labs(title="Adj. Wage Share", caption = "Quelle: AMECO") +
  scale_y_continuous(
    name="Lohnanteil in %", 
    expand = expansion(c(0, 0), c(0,5)), 
    labels = scales::percent_format(accuracy = 1, scale = 1)
    ) +
  theme_bw() +
  coord_flip() +
  theme(axis.title.y = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(), 
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank(), 
        panel.grid.minor.y = element_blank())

gini_plot <- ggplot(
  data = ameco_swiid_data, 
  mapping = aes(x=Region, y=gini_disp_mean)
  ) +
  geom_bar(
    stat = "identity", width = 0.5, color="#13294b", fill="#13294b"
    ) +
  geom_errorbar(
    aes(ymin=gini_disp_mean-0.5*AWS_sd, ymax=gini_disp_mean+0.5*AWS_sd), 
    width = 0.4, color = "grey"
    ) +
  labs(title="Gini (post-Steuer)", caption = "Quelle: SWIID") +
  scale_y_continuous(
    name="Gini (post-Steuer)", 
    expand = expansion(c(0, 0), c(0,5)), 
    labels = scales::percent_format(accuracy = 1, scale = 1)
    ) +
  coord_flip() +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(), 
        axis.ticks.y = element_blank(), 
        panel.grid.major.y = element_blank(), 
        panel.grid.minor.y = element_blank())

full_plot <- ggpubr::ggarrange(aws_plot, gini_plot, nrow = 2)
```

```{r, eval=FALSE}
ggsave(plot = full_plot, 
       filename = here("output/vis_ameco_swiid.png"), 
       width = 6, height = 4)
```



# Formalia

TBA

# Regressionsanalyse I

TBA

# Monte-Carlo-Simulationen

## Der Zentrale Grenzwertsatz

```{r}
require(tidyverse)
require(ggpubr)
require(icaeDesign)
```


```{r}
set.seed(123)
n_samples <- c(5, 10, 50, 500, 1000, 5000)
sample_means <- list()
mean_plots <- list()
for (i in seq_along(n_samples)){
  sample_means[[paste0("n_", n_samples[i])]] <- tibble(
    means = purrr::map_dbl(
      .x = 1:n_samples[i], .f = ~mean(runif(n = 20)))
    )
  mean_plots[[paste0("n_", n_samples[i])]] <- ggplot(
    data = sample_means[[paste0("n_", n_samples[i])]],
    mapping = aes(x=means)
  ) +
    labs(title = paste0("Stichprobe: ", n_samples[i])) +
    geom_density() + theme_icae()
}
```

Beachten Sie die Verwendung der Funktion `purrr::map_dbl()`, mit der wir
das gleiche wie mit einem einfachen `for`-Loop erreichen können. Sie führt
die Funktion nach dem Argument `.f` so oft aus wie der Vektor beim Argument
`.x` lang ist und gibt die Ergebnisse als Vektor aus. Für mehr Infos siehe 
z.B. [hier](https://r4ds.had.co.nz/iteration.html#the-map-functions).

```{r}
ggpubr::ggarrange(plotlist = mean_plots)
```

## Das Gesetz der großen Zahl

```{r}
require(tidyverse)
require(ggpubr)
require(icaeDesign)
```

```{r}
set.seed(1)
samples <- 20
nb_samples <- 500
sample_sizes <- seq(10, 10000, length.out = samples)
sample_means <- rep(NA, samples)
sample_vars <- rep(NA, samples)
for (i in 1:samples){
  sample_size <- sample_sizes[i]
  
  samples_used <- purrr::map_dbl(.x = 1:nb_samples, .f = ~mean(
    rnorm(n = sample_size, mean = 0, sd = 2))
    )
  sample_means[i] <- mean(samples_used)
  sample_vars[i] <- sd(samples_used)
}

mean_plot <- ggplot(
  tibble(sample_sizes, sample_means), aes(x=sample_sizes, y=sample_means)
  ) +
  geom_line() + geom_hline(yintercept = 0) +
  ggtitle("Mean sample means") +
  theme_icae()

var_plot <- ggplot(
  tibble(sample_sizes, sample_vars), aes(x=sample_sizes, y=sample_vars)
  ) +
  ggtitle("Variance of sample means") +
  geom_line() + 
  theme_icae()

ggpubr::ggarrange(mean_plot, var_plot)
```


## OLS und nicht-normalverteilte Fehler

```{r}
require(tidyverse)
require(data.table)
require(knitr)
require(icaeDesign)
```


Spezifikation der Parameter:

```{r}
set.seed(123)
mcs_runs <- 1000
beta_0 <- 1
beta_1 <- 3
stichproben_n <- c(10, 20, 50, 100)
```

Definition einer Funktion, welche die MCS für eine gegebene Stichprobengröße
ausführt:

```{r}
do_mcs <- function(stichprobengroesse, mcs_runs){
  # Erstellen der deterministischen Variablen:
  x_var <- runif(stichprobengroesse)
  y_determ <- beta_0 + beta_1*x_var
  data_det <- tibble("x"=x_var, "y_det"=y_determ)
  beta_1hat_norm <- rep(NA, mcs_runs)
  beta_1se_norm <- rep(NA, mcs_runs)
  beta_1hat_chi <- rep(NA, mcs_runs)
  beta_1se_chi <- rep(NA, mcs_runs)
  for (i in 1:mcs_runs){
    # Ziehung der Fehlerterme und Berechnung der Stichprobe
    normal_errors <- scale(rnorm(n = stichprobengroesse))
    nonnormal_errors <- scale(rchisq(n = stichprobengroesse, df = 1))
    sample_obtained <- data_det %>%
      dplyr::mutate(
        y_norm = y_det + normal_errors,
        y_chi = y_det + nonnormal_errors[,1]
      )
  
    # Schätzung des Modells
    linreg_norm <- summary(lm(y_norm~x, data = sample_obtained))
    beta_1hat_norm[i] <- coef(linreg_norm)[2]
    beta_1se_norm[i] <- coef(linreg_norm)[4]
    
    linreg_chi <- summary(lm(y_chi~x, data = sample_obtained))
    beta_1hat_chi[i] <- coef(linreg_chi)[2]
    beta_1se_chi[i] <- coef(linreg_chi)[4]
  }
  tibble(
    "n" = rep(stichprobengroesse, mcs_runs), 
    "beta_1hat_norm" = beta_1hat_norm,
    "beta_1se_norm" = beta_1se_norm,
    "beta_1hat_chi" = beta_1hat_chi,
    "beta_1se_chi" = beta_1se_chi
  )
}

```

Simulation für verschiedene Stichprobengrößen:

```{r}
mcs_results <- list()
for (i in seq_along(stichproben_n)){
  mcs_results[[i]] <- do_mcs(
    stichprobengroesse = stichproben_n[i], mcs_runs = mcs_runs)
}
mcs_results_full <- data.table::rbindlist(mcs_results)
```

Visualisierung der Ergebnisse:

```{r}
mcs_results_full %>%
  select(all_of(c("beta_1hat_norm", "beta_1hat_chi", "n"))) %>%
  pivot_longer(
    cols = all_of(c("beta_1hat_norm", "beta_1hat_chi")), 
    names_to = "vars", values_to = "values") %>%
  dplyr::mutate(stichprobe=factor(n)) %>%
  ggplot(data = ., aes_string(x="values", color="vars", fill="vars")) +
  geom_density(alpha=0.5) +
  scale_color_viridis_d(aesthetics = c("color", "fill")) +
  facet_wrap(~stichprobe) +
  theme_icae()
```

```{r}
mcs_results_full %>%
  select(all_of(c("beta_1se_chi",  "beta_1se_norm", "n"))) %>%
  pivot_longer(
    cols = all_of(c("beta_1se_norm", "beta_1se_chi")), 
    names_to = "vars", values_to = "values") %>%
  dplyr::mutate(stichprobe=factor(n)) %>%
  ggplot(data = ., aes_string(x="values", color="vars", fill="vars")) +
  geom_density(alpha=0.5) +
  scale_color_viridis_d(aesthetics = c("color", "fill")) +
  facet_wrap(~stichprobe) +
  theme_icae()
```
          
Zusammenfassende Statistiken:

```{r}
mcs_results_full %>%
  dplyr::mutate(
    sq_errors_normal = (beta_1hat_norm - beta_1)**2,
    sq_errors_chi = (beta_1hat_chi - beta_1)**2
  ) %>%
  group_by(n) %>%
  summarise(
    mean_beta1_hat_norm=mean(beta_1hat_norm),
    mean_beta1_hat_chi=mean(beta_1hat_chi),
    mean_se_norm = mean(beta_1se_norm),
    mean_se_chi = mean(beta_1se_chi),
    mse_beta1_norm=mean(sq_errors_normal),
    mse_beta_1_chi=mean(sq_errors_chi)
  ) %>%
  knitr::kable(
    digits = 3, 
    col.names = c("n", "B1 (norm)", "B1 (chi)", "SE (norm)",
                  "SE (chi)", "MSE (norm)", "MSE (chi)"))
```

Insgesamt sind also bereits bei sehr kleinen Stichproben kaum 
Performance-Unterschiede zu erkennen.

# Regressionsanalyse II

TBA

# Regressionsanalyse III

TBA